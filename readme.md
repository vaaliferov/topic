
#### Краткое описание
* В данном репозитории находится решение задачи классификации текстов (~450к документов) 
* Категории документов: Интернет и СМИ, Культура, Мир, Наука и техника, Спорт, Экономика


#### Список тетрадок

* **00**. Анализ данных
* **01**. Предобработка данных
* **02**. Логистическая регрессия (TFIDF+SVD)
* **03**. Извлечение статических эмбеддингов (TFIDF+SVD, Word2Vec+SVD)
* **04**. Логистическая регрессия на базе статических эмбеддингов (TFIDF+SVD, Word2Vec+SVD)
* **05**. Градиентный бустинг на базе CatBoost (используя встроенный текстовый векторайзер)
* **06**. Пайплайн для классификации новых текстов для 3х вышеописанных моделей
* **07**. Нейросетевой классификатор на базе предобученной модели rubert-tiny2
* **08**. Пайплайн для классификации новых текстов для модели из предыдущего пункта
* **09**. Визуализация латентного пространства (статические эмбеддинги TFIDF+SVD, Word2Vec+SVD)
* **10**. Визуализация латентного пространства (контекстные эмбеддинги cls токена модели rubert-tiny2)
* **11**. Список файлов в директории data с указанием их размера (датасет, корпус, веса моделей и т.д.)
* **12**. Бонус: решил повторить sql join'ы, к данному проекту отношения не имеет :)
* **13**. Модели CNN, SepCNN, LSTM на базе предобученных статических эмбеддингов


#### Дальнейшие планы
* Подбор гиперпараметров, выбор лучшей модели (GridSearchCV, Optuna)
* Классификаторы на базе статических эмбеддингов из BM25 векторайзера
* Классификаторы на основе KNN, SVM, Random Forest (статические эмбеддинги)
* Классификаторы на базе CNN / RNN / CNN + RNN (используя статические эмбеддинги)
* Дистиляция, квантизация, каскадирование, прунинг (для модели на базе rubert-tiny2)
* Подробное тестирование и сравнение производительности классических и нейросетевых моделей


#### Воспроизводимость результатов

```bash
git clone https://github.com/vaaliferov/topic.git
```

Содержимое директории `data` можно скачать 
[здесь](https://drive.google.com/file/d/1XtD2IG-WTiP_jKauQ8MGIPdv4uV5uiY8/view?usp=share_link).