{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d38c309-e5de-4d58-893c-b3a7566cb767",
   "metadata": {},
   "source": [
    "#### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de360934-79d5-4eb9-b80c-36df32f533ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymystem3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa4042-3880-4bd2-92d5-2c7f01f87759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386eadaf-4a14-4b47-ac9a-11579053eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    s = re.sub('\\n', ' ', s) # 1\n",
    "    s = re.sub('<\\?xml.+\\?>', ' ', s) # 2\n",
    "    s = re.sub('<\\/?[A-Za-z]*>', ' ', s) # 3\n",
    "    s = re.sub('[0-9]+(\\.|,)?[0-9]*', ' num ', s) # 4\n",
    "    s = re.sub('([a-zа-яёй])([A-ZА-ЯЁЙ])', '\\g<1> \\g<2>', s) # 5\n",
    "    s = re.sub('[^A-Za-zА-ЯЁЙа-яёй0-9\\s\\-]', ' ', s) # 6\n",
    "    return re.sub('\\s{2,}', ' ', s).strip().lower() # 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21cb8b-8e4e-4446-89cc-3406ccd92ad1",
   "metadata": {},
   "source": [
    "1. *удаляем символы переноса строки `\\n`*\n",
    "2. *удаляем `< ?xml version=\"1.0\" encoding=\"utf-8\"? >`*\n",
    "3. *удаляем `< conversion >`, `< person >` и прочие теги*\n",
    "4. *заменяем числа `13`, `13.3`, `13,3` на тег `num`*\n",
    "5. *\"расклеиваем\" слова (где это очевидно) `болееТысячи` -> `более Тысячи`*\n",
    "6. *оставляем только символы латинского алфавита и кириллицы, а также цифры, пробелы и дефисы*\n",
    "7. *удаляем лишние пробелы, удаляем пробелы слева и справа, приводим к нижнему регистру*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2037b-f944-431e-bcd8-8cdd246987b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return re.findall('[.,;:!?()\"]|\\w+-\\w+|\\w+\\'\\w+|\\w+|-|\\'', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2598227-3868-4aed-93c2-50eed9aa042a",
   "metadata": {
    "tags": []
   },
   "source": [
    "* *разделяем текст на токены:*\n",
    "* *символы из последовательности `.,;:!?()\"`*\n",
    "* *слова с дефисом `кто-то` и апострофом `didn't` (мало ли :)*\n",
    "* *одиночные слова, а также символы дефиса и апострофа отдельно*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65be28-8096-44e1-9885-243a3e07d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(words, stem):\n",
    "    return [stem.lemmatize(w)[0].strip() for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89622505-6e5f-4012-b9b6-bd27adcbb98f",
   "metadata": {},
   "source": [
    "* *производим лемматизацию: `тысячи` -> `тысяча`*\n",
    "* *удаляем символ `\\n` (особенность pymystem3)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290806a5-9660-45e4-8bb0-fdace200bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words, stopwords):\n",
    "    return [w for w in words if w not in set(stopwords)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509f1c8-690b-4750-a0fa-ddb3ba1b46af",
   "metadata": {},
   "source": [
    "* *удаляем стоп-слова (слишком часто встречающиеся и потому не несущие полезную информацию)*\n",
    "* *имеет смысл поискать такой список под данный коркретный домен (к которому относятся наши тексты)*\n",
    "* *кроме того, думаю, имеет смысл найти / создать список стоп-слов, которые не нужно лемматизировать*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694376a5-8c9a-40d3-bd79-7f27c34eaa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem, stopwords):\n",
    "    words = lemmatize(tokenize(clean(text)), stem)\n",
    "    return ' '.join(remove_stopwords(words, stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3165241-8feb-441e-a417-eb3cf7d1b10a",
   "metadata": {},
   "source": [
    "* *объединяем все вместе: на входе исходный текст, на выходе - предобработанный*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f802bef-1e06-41f2-9bcf-70abebc9f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "stem = pymystem3.Mystem()\n",
    "s1 = load_lines('data/iso_stopwords_ru.txt')\n",
    "s2 = load_lines('data/nltk_stopwords_en.txt')\n",
    "fp = lambda s: preprocess(s, stem, s1 + s2)\n",
    "df = pd.read_csv('data/raw.csv', nrows=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48540bd-89b9-4cd0-a1aa-9f610fecd060",
   "metadata": {},
   "source": [
    "* *инициализируем pymystem3*\n",
    "* *загружаем список стоп-слов*\n",
    "* *загружаем исходный датафрейм*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad7956-56a1-4d9c-b384-5c93661401f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = encode_labels(df['topic'])\n",
    "df['topic'] = df['topic'].map(labels)\n",
    "df['text'] = df['text'].progress_apply(fp)\n",
    "df['title'] = df['title'].progress_apply(fp)\n",
    "df['title_len'] = df['title'].str.len()\n",
    "df['text_len'] = df['text'].str.len()\n",
    "dump_json(labels, 'data/labels.json')\n",
    "df.to_feather('data/prep.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d61891-6634-4edd-8e02-9cf40a7afcd2",
   "metadata": {},
   "source": [
    "* *предобрабатываем тексты и заголовоки*\n",
    "* *формируем новые признаки: text_len и title_len*\n",
    "* *кодируем целевые метки и сохраняем их в json файл*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49218e51-255a-464d-a53c-5311369d1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['title'] + ' ' + df['text']\n",
    "dump_lines(corpus, 'data/corpus.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3da97-93f3-425d-97a1-4ba75c4519d7",
   "metadata": {},
   "source": [
    "* *сохраняем корпус текстов в отдельный файл для удобства последующего предобучения*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
