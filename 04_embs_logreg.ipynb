{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a697809-683c-4c78-bc4d-8a81b7de7668",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия на базе статических эмбеддингов (TFIDF+SVD, Word2Vec+SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8393e854-244a-47f6-b0e1-75fa00e52130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b366919-2b26-4ab9-b92c-2943920f6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f72a95-4c20-4b12-973d-3cf32fd19d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d8476e-8348-4a0d-b4f1-b6de8fc43fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7a73f4-25d7-4d69-8ff9-2dcf30d93298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, emb_dict):\n",
    "    \n",
    "    embs = [emb_dict[w] for w in text.split() if w in emb_dict]\n",
    "    \n",
    "    if len(embs) == 0: \n",
    "        first_key = next(iter(emb_dict.keys()))\n",
    "        return np.zeros(emb_dict[first_key].shape)\n",
    "    \n",
    "    return np.vstack(embs).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452b5fd-f7b8-4bd7-ba34-34d88caa6bac",
   "metadata": {},
   "source": [
    "* *функция для извлечения эмбеддинга документа (последовательности слов)*\n",
    "* *делим предобработанный текст на слова, получаем эмбеддинг для каждого из них (из словаря)*\n",
    "* *если данное слово отсутствует в словаре, пропускаем его (формируем список эмбеддингов)*\n",
    "* *возвращаем вектор средних значений по каждому признаку для слов (эмбеддинг документа)*\n",
    "* *в случае, если ни одно из слов не было найдено в словаре, возвращаем вектор нулевых значений*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b82a5-0f4c-4e0a-8d03-9bb2171eedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df = pd.read_feather('data/prep.ftr')\n",
    "emb_dict = load_pickle('data/w2v_embs.bin')\n",
    "\n",
    "ge = lambda s: get_embedding(s, emb_dict)\n",
    "text_series = df['title'] + ' ' + df['text']\n",
    "text_embs = text_series.progress_apply(ge)\n",
    "text_embs = np.vstack(text_embs.to_numpy())\n",
    "\n",
    "text_len = np.expand_dims(df['text_len'].to_numpy(), axis=1)\n",
    "title_len = np.expand_dims(df['title_len'].to_numpy(), axis=1)\n",
    "\n",
    "X = np.hstack((text_embs, title_len, text_len))\n",
    "y = df['topic'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d41725-1ac6-458b-9a23-b650bff3e972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((432158, 300), (432158, 302), (432158,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embs.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53694d5b-e660-4d54-b560-3816842ba4ea",
   "metadata": {},
   "source": [
    "* *загружаем предобработанный датафрейм*\n",
    "* *загружаем словарь эмбеддингов слов (TFIDF или Word2Vec)*\n",
    "* *склеиваем title и text для каждого из документов*\n",
    "* *извлекаем эмбеддинги для каждого документа (по 300 фичей на документ)*\n",
    "* *приклеиваем к кадждому из этих эмбеддингов еще по 2а признака: text_len и title_len*\n",
    "* *в результате получаем 432158 примера (302 признака в каждом), а также 432158 целевых метки класса*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19264ac-85d0-4727-8cad-ff36b87b0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'stratify': y, 'test_size': 0.2, 'random_state': 42}\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65476343-9198-4795-9ecf-5910d003af9f",
   "metadata": {},
   "source": [
    "* *делим данные на 2е части: 80% для обучения, стратификация по целевой переменной*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ad87ca-3d67-4363-9ef5-5b7dd95a97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 51s, sys: 1.4 s, total: 10min 52s\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'solver': 'liblinear'\n",
    "}\n",
    "\n",
    "logreg = Pipeline([\n",
    "    ('sca', StandardScaler()), \n",
    "    ('clf', LogisticRegression(**params))\n",
    "])\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c3985-46f7-4be6-980c-88588cd4508f",
   "metadata": {},
   "source": [
    "* *собираем pipeline на базе логистической регрессии*\n",
    "* *будем выполнять нормализацию всех 302х признаков для каждого объекта*\n",
    "* *обучаем полученный pipeline, формируем предсказания на валидационной части данных*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ed0fb1-37c8-4991-856d-cb103fb5b913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925733524620511"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237c73e-0a8b-41b7-a182-2708f96c4cd3",
   "metadata": {},
   "source": [
    "* *на эмбеддингах из TFIDF: acc = 0.9157372269529804*\n",
    "* *на эмбеддингах из Word2Vec: acc = 0.925733524620511*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6332f19b-c078-47d9-aac1-838356cc1fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182387016356302"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_valid, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee7d3b-7d8c-4eb1-a296-373069027ad9",
   "metadata": {},
   "source": [
    "* *на эмбеддингах из TFIDF: f1 = 0.9072066831050293*\n",
    "* *на эмбеддингах из Word2Vec: f1 = 0.9182387016356302*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035522df-7648-426c-aff3-413c2407e2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7253   309   658   312    79   322]\n",
      " [  235 10076   302    77    21    48]\n",
      " [  360   236 25719   468    98   443]\n",
      " [  342   126   552  9395    12   200]\n",
      " [   58    21   114    21 12642    27]\n",
      " [  239    56   501   132    50 14928]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3619e84-c737-479d-b3e4-a395f54afe7f",
   "metadata": {},
   "source": [
    "* *последний запуск был на Word2Vec эмбеддингах*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f327c6d-f7ca-4176-a212-0c9d36ce1d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      8933\n",
      "           1       0.93      0.94      0.93     10759\n",
      "           2       0.92      0.94      0.93     27324\n",
      "           3       0.90      0.88      0.89     10627\n",
      "           4       0.98      0.98      0.98     12883\n",
      "           5       0.93      0.94      0.94     15906\n",
      "\n",
      "    accuracy                           0.93     86432\n",
      "   macro avg       0.92      0.92      0.92     86432\n",
      "weighted avg       0.93      0.93      0.93     86432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b48496-c48a-4cae-9b88-d31f52a476f1",
   "metadata": {},
   "source": [
    "* *последний запуск был на Word2Vec эмбеддингах*\n",
    "* *опять же, видно, что хуже всего модель справляется с классом 0 (Интернет и СМИ)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d93593d-cac3-49c8-9c6e-c3e1eddf501f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Интернет и СМИ', 'Культура', 'Мир', 'Наука и техника', 'Спорт', 'Экономика']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(load_json('data/labels.json').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0c68aac-0644-4832-866c-858354f28b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(logreg, 'data/w2v_embs_logreg.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3882ea-e775-41ff-b4fd-a986d4a5da47",
   "metadata": {},
   "source": [
    "* *размер файла модели: ~22k*\n",
    "* *размер файла словаря эмбеддингов TFIDF: ~41Мб*\n",
    "* *размер файла словаря эмбеддингов Word2Vec: ~61Мб*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
